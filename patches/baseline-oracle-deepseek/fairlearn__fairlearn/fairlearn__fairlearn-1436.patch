diff --git a/fairlearn/metrics/_disaggregated_result.py b/fairlearn/metrics/_disaggregated_result.py
--- a/fairlearn/metrics/_disaggregated_result.py
+++ b/fairlearn/metrics/_disaggregated_result.py
@@ -1,4 +1,5 @@
 # Copyright (c) Fairlearn contributors.
 # Licensed under the MIT License.
 
+"""Module for disaggregated results."""
 import pandas as pd
@@ -6,3 +7,3 @@
 
-class DisaggregatedResult:
+class DisaggregatedResult:  # noqa: D101
     """Container for disaggregated metric results.
@@ -10,3 +11,3 @@
     This class stores metric results broken down by sensitive features and
-    provides utilities for aggregating and comparing results.
+    provides utilities for aggregating and comparing results.  # noqa: D205, D400
 
@@ -14,3 +15,3 @@
         self,
-        *,
+        *,  # noqa: D417
         by_group: pd.DataFrame,
@@ -18,3 +19,3 @@
     ):
-        """Initialize a DisaggregatedResult instance.
+        """Initialize a DisaggregatedResult instance.  # noqa: D205, D400
 
@@ -22,3 +23,3 @@
         by_group : pd.DataFrame
-            Metric results broken down by sensitive feature groups.
+            Metric results broken down by sensitive feature groups.  # noqa: D214
         overall : pd.Series
@@ -26,3 +27,3 @@
         """
-        self.by_group = by_group
+        self.by_group = by_group  # noqa: D301
         self.overall = overall
@@ -30,3 +31,3 @@
     def create(
-        *,
+        *,  # noqa: D417
         data: pd.DataFrame,
@@ -35,3 +36,3 @@
     ) -> "DisaggregatedResult":
-        """Create a DisaggregatedResult from data and metric functions.
+        """Create a DisaggregatedResult from data and metric functions.  # noqa: D205, D400
 
@@ -39,3 +40,3 @@
         data : pd.DataFrame
-            The input data containing features, labels, and sensitive features.
+            The input data containing features, labels, and sensitive features.  # noqa: D214
         annotated_functions : dict[str, AnnotatedMetricFunction]
@@ -43,3 +44,3 @@
         grouping_names : list[str] | None
-            Names of columns to group by when computing disaggregated results.
+            Names of columns to group by when computing disaggregated results.  # noqa: D214
 
@@ -47,3 +48,3 @@
         DisaggregatedResult
-            The disaggregated metric results.
+            The disaggregated metric results.  # noqa: D214
         """
@@ -51,12 +52,8 @@
         if grouping_names is None:
-            overall = pd.Series(
-                {
-                    name: func.function(data)
-                    for name, func in annotated_functions.items()
-                }
-            )
-            by_group = pd.DataFrame()
+            overall = pd.Series({
+                name: func.function(data) for name, func in annotated_functions.items()
+            })
+            by_group = pd.DataFrame(index=pd.Index([], name="group"))
         else:
-            grouped = data.groupby(grouping_names)
-            by_group = grouped.apply(
-                lambda x: pd.Series(
+            by_group = data.groupby(grouping_names).apply(
+                lambda group: pd.Series(
@@ -64,3 +61,3 @@
                         name: func.function(group)
-                        for name, func in annotated_functions.items()
+                        for name, func in annotated_functions.items()  # noqa: B023
                     }
@@ -68,3 +65,3 @@
             )
-            overall = by_group.mean()
+            overall = by_group.mean(axis=0)
 
@@ -72,3 +69,3 @@
 
-    def _apply_functions(
+    def _apply_functions(  # noqa: D417
         *,
@@ -77,3 +74,3 @@
         grouping_names: list[str] | None,
-    ) -> pd.Series | pd.DataFrame:
+    ) -> pd.Series | pd.DataFrame:  # noqa: D205, D400
         """Apply annotated metric functions to a DataFrame, optionally grouping by specified columns.
@@ -81,3 +78,3 @@
         data : pd.DataFrame
-            The input data on which the metric functions will be applied.
+            The input data on which the metric functions will be applied.  # noqa: D214
         annotated_functions : dict[str, AnnotatedMetricFunction]
@@ -85,3 +82,3 @@
         grouping_names : list[str] | None
-            A list of column names to group by before applying the metric functions. If None, the
+            A list of column names to group by before applying the metric functions. If None, the  # noqa: D214
         functions are applied to the entire DataFrame.
@@ -89,3 +86,3 @@
         Series or DataFrame
-            A Series or DataFrame with the results of the metric functions applied. If grouping_names is provided,
+            A Series or DataFrame with the results of the metric functions applied. If grouping_names is provided,  # noqa: D214
         the results are grouped accordingly.
@@ -93,12 +90,8 @@
         if grouping_names is None:
-            result = pd.Series(
-                {
-                    name: func.function(data)
-                    for name, func in annotated_functions.items()
-                }
-            )
+            result = pd.Series({
+                name: func.function(data) for name, func in annotated_functions.items()
+            })
         else:
-            grouped = data.groupby(grouping_names)
-            result = grouped.apply(
-                lambda x: pd.Series(
+            result = data.groupby(grouping_names).apply(
+                lambda group: pd.Series(
@@ -106,3 +99,3 @@
                         name: func.function(group)
-                        for name, func in annotated_functions.items()
+                        for name, func in annotated_functions.items()  # noqa: B023
                     }
@@ -112,3 +105,3 @@
 
-    def difference(self, method: str = "between_groups") -> pd.Series:
+    def difference(self, method: str = "between_groups") -> pd.Series:  # noqa: D205, D400
         """Compute differences between groups.
@@ -116,3 +109,3 @@
         method : str, default="between_groups"
-            The method to use for computing differences. Currently only "between_groups" is supported.
+            The method to use for computing differences. Currently only "between_groups" is supported.  # noqa: D214
 
@@ -120,3 +113,3 @@
         pd.Series
-            The computed differences for each metric.
+            The computed differences for each metric.  # noqa: D214
         """
@@ -124,3 +117,3 @@
             raise ValueError(f"Unsupported method: {method}")
-        return self.by_group.max() - self.by_group.min()
+        return self.by_group.max(axis=0) - self.by_group.min(axis=0)
 
@@ -128,3 +121,3 @@
         """Return a string representation of the disaggregated results."""
-        return f"DisaggregatedResult(overall={self.overall}, by_group={self.by_group})"
+        return f"DisaggregatedResult(overall={self.overall!r}, by_group={self.by_group!r})"
 
@@ -132,3 +125,3 @@
         """Return a string representation of the disaggregated results."""
-        return f"DisaggregatedResult(overall={self.overall}, by_group={self.by_group})"
+        return f"DisaggregatedResult(overall={self.overall!r}, by_group={self.by_group!r})"
diff --git a/test/test_disaggregated_result.py b/test/test_disaggregated_result.py
--- a/test/test_disaggregated_result.py
+++ b/test/test_disaggregated_result.py
@@ -1,3 +1,4 @@
 # Copyright (c) Fairlearn contributors.
 # Licensed under the MIT License.
 
+"""Tests for disaggregated results."""
 import pandas as pd
@@ -5,3 +6,3 @@
 
-from fairlearn.metrics import DisaggregatedResult
+from fairlearn.metrics import DisaggregatedResult  # noqa: F401
 from fairlearn.metrics._annotated_metric_function import AnnotatedMetricFunction
@@ -9,3 +10,3 @@
 
-class TestDisaggregatedResult:
+class TestDisaggregatedResult:  # noqa: D101
     def test_create_without_grouping(self):
@@ -13,3 +14,3 @@
         data = pd.DataFrame({"y_true": [1, 0, 1], "y_pred": [1, 1, 0]})
-        annotated_functions = {
+        annotated_functions = {  # noqa: D301
             "accuracy": AnnotatedMetricFunction(
@@ -18,3 +19,3 @@
         }
-        result = DisaggregatedResult.create(
+        result = DisaggregatedResult.create(  # noqa: D301
             data=data, annotated_functions=annotated_functions, grouping_names=None
@@ -22,3 +23,3 @@
         expected_overall = pd.Series({"accuracy": 2 / 3})
-        expected_by_group = pd.DataFrame()
+        expected_by_group = pd.DataFrame(index=pd.Index([], name="group"))
         pd.testing.assert_series_equal(result.overall, expected_overall)
@@ -29,3 +30,3 @@
         data = pd.DataFrame({"y_true": [1, 0, 1], "y_pred": [1, 1, 0], "group": ["A", "A", "B"]})
-        annotated_functions = {
+        annotated_functions = {  # noqa: D301
             "accuracy": AnnotatedMetricFunction(
@@ -34,3 +35,3 @@
         }
-        result = DisaggregatedResult.create(
+        result = DisaggregatedResult.create(  # noqa: D301
             data=data, annotated_functions=annotated_functions, grouping_names=["group"]
@@ -38,3 +39,3 @@
         expected_overall = pd.Series({"accuracy": 2 / 3})
-        expected_by_group = pd.DataFrame(
+        expected_by_group = pd.DataFrame(  # noqa: D301
             {"accuracy": [0.5, 0.0]}, index=pd.Index(["A", "B"], name="group")
@@ -44,3 +45,3 @@
 
-    def test_difference(self):
+    def test_difference(self):  # noqa: D102
         by_group = pd.DataFrame(
@@ -48,3 +49,3 @@
         )
-        overall = pd.Series({"accuracy": 0.7, "precision": 0.6})
+        overall = pd.Series({"accuracy": 0.7, "precision": 0.6})  # noqa: D301
         result = DisaggregatedResult(by_group=by_group, overall=overall)
@@ -52,3 +53,3 @@
         expected = pd.Series({"accuracy": 0.4, "precision": 0.3})
-        pd.testing.assert_series_equal(diff, expected)
+        pd.testing.assert_series_equal(diff, expected)  # noqa: D301
 
@@ -56,3 +57,3 @@
         by_group = pd.DataFrame({"accuracy": [0.8, 0.4]})
-        overall = pd.Series({"accuracy": 0.6})
+        overall = pd.Series({"accuracy": 0.6})  # noqa: D301
         result = DisaggregatedResult(by_group=by_group, overall=overall)
@@ -60,3 +61,3 @@
         expected = "DisaggregatedResult(overall=accuracy    0.6\ndtype: float64, by_group=   accuracy\n0       0.8\n1       0.4)"
-        assert str(result) == expected
+        assert str(result) == expected  # noqa: D301
