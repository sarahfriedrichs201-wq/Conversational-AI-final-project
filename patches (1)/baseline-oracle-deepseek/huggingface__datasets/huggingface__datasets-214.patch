diff --git a/src/datasets/arrow_dataset.py b/src/datasets/arrow_dataset.py
--- a/src/datasets/arrow_dataset.py
+++ b/src/datasets/arrow_dataset.py
@@ -1,4 +1,5 @@
 import copy
+import itertools
 import json
 import os
 import pickle
@@ -6,6 +7,7 @@
 import warnings
 from collections import defaultdict
 from dataclasses import asdict, dataclass, field
+from functools import partial
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
@@ -14,6 +16,7 @@
 from datasets import config
 from datasets.arrow_writer import ArrowWriter, OptimizedTypedSequence
 from datasets.features import Features, Sequence, Value, cast_to_python_objects
+from datasets.fingerprint import update_fingerprint
 from datasets.info import DatasetInfo
 from datasets.search import ElasticSearchIndex, FaissIndex, MissingIndex
 from datasets.table import (
@@ -25,6 +28,7 @@
     table_cast,
     table_iter,
 )
+from datasets.utils.logging import get_logger
 from datasets.utils.py_utils import (
     asdict,
     dumps,
@@ -35,6 +39,8 @@
     size_str,
 )
 
+logger = get_logger(__name__)
+
 
 class DatasetInfoMixin:
     """Base class for Dataset and IterableDataset that contains info property"""
@@ -176,6 +182,7 @@
         "remove_columns",
         "keep_in_memory",
         "load_from_cache_file",
+        "cache_file_name",
         "writer_batch_size",
         "features",
         "disable_nullable",
@@ -184,6 +191,7 @@
         "desc",
         "fn_kwargs",
         "num_proc",
+        "suffix_type",
     ]
 
     def __init__(
@@ -204,6 +212,7 @@
         remove_columns: Optional[List[str]] = None,
         keep_in_memory: bool = False,
         load_from_cache_file: bool = True,
+        cache_file_name: Optional[str] = None,
         writer_batch_size: Optional[int] = 1000,
         features: Optional[Features] = None,
         disable_nullable: bool = False,
@@ -212,6 +221,7 @@
         desc: Optional[str] = None,
         fn_kwargs: Optional[dict] = None,
         num_proc: Optional[int] = None,
+        suffix_type: Optional[str] = None,
     ):
         self.input_dataset = input_dataset
         self.function = function
@@ -226,6 +236,7 @@
         self.remove_columns = remove_columns
         self.keep_in_memory = keep_in_memory
         self.load_from_cache_file = load_from_cache_file
+        self.cache_file_name = cache_file_name
         self.writer_batch_size = writer_batch_size
         self.features = features
         self.disable_nullable = disable_nullable
@@ -234,6 +245,7 @@
         self.desc = desc
         self.fn_kwargs = fn_kwargs if fn_kwargs is not None else {}
         self.num_proc = num_proc
+        self.suffix_type = suffix_type
 
     def __call__(self):
         """Apply transformation"""
@@ -248,6 +260,7 @@
             remove_columns=self.remove_columns,
             keep_in_memory=self.keep_in_memory,
             load_from_cache_file=self.load_from_cache_file,
+            cache_file_name=self.cache_file_name,
             writer_batch_size=self.writer_batch_size,
             features=self.features,
             disable_nullable=self.disable_nullable,
@@ -256,6 +269,7 @@
             desc=self.desc,
             fn_kwargs=self.fn_kwargs,
             num_proc=self.num_proc,
+            suffix_type=self.suffix_type,
         )
 
 
@@ -273,6 +287,7 @@
         remove_columns: Optional[List[str]] = None,
         keep_in_memory: bool = False,
         load_from_cache_file: bool = True,
+        cache_file_name: Optional[str] = None,
         writer_batch_size: Optional[int] = 1000,
         features: Optional[Features] = None,
         disable_nullable: bool = False,
@@ -281,6 +296,7 @@
         desc: Optional[str] = None,
         fn_kwargs: Optional[dict] = None,
         num_proc: Optional[int] = None,
+        suffix_type: Optional[str] = None,
     ) -> "Dataset":
         """Apply a function to all the elements in the table in batches
         and update the table so that the dataset only includes examples according to the filter function.
@@ -290,6 +306,8 @@
                 - `function(example: Dict) -> bool` if `with_indices=False`
                 - `function(example: Dict, indices: int) -> bool` if `with_indices=True`
             with_indices (`bool`, default: `False`): Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.
+            input_columns (`Optional[List[str]]`, default: `None`): The columns to be passed into `function` as
+                positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.
             batch_size (`Optional[int]`, default: `1000`): Number of examples per batch provided to `function` if `batched=True`
                 `batch_size <= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`
             remove_columns (`Optional[List[str]]`, default: `None`): Remove a selection of columns while doing the mapping.
@@ -298,6 +316,8 @@
             keep_in_memory (`bool`, default: `False`): Keep the dataset in memory instead of writing it to a cache file.
             load_from_cache_file (`bool`, default: `True`): If a cache file storing the current computation from `function`
                 can be identified, use it instead of recomputing.
+            cache_file_name (`Optional[str]`, default: `None`): Provide the name of a cache file to use to store the
+                results of the computation instead of the automatically generated cache file name.
             writer_batch_size (`int`, default: `1000`): Number of rows per write operation for the cache file writer.
                 Higher value gives smaller cache files, lower value consume less temporary memory while running `.map()`.
             disable_nullable (`bool`, default: `True`): Allow null values in the table.
@@ -305,6 +325,8 @@
                 `function` returns a dict, the key in the output dict. If not provided, will use the key from the input dict if `function` returns a dict.
             desc (`Optional[str]`, default: `None`): Meaningful description to be displayed alongside with the progress bar while mapping examples.
             fn_kwargs (`Optional[Dict]`, default: `None`): Keyword arguments to be passed to `function`
+            num_proc (`Optional[int]`, default: `None`): Number of processes for multiprocessing. By default it doesn't
+                use multiprocessing.
             suffix_type (`Optional[str]`, default: `None`): Suffix type for the cache file name. If not provided, will use the default suffix type.
 
         Returns:
@@ -312,6 +334,7 @@
         """
         assert num_proc is None or num_proc == 1, "filter doesn't support multiprocessing yet"
 
+        # Transform the filter function into a map function that returns the example if filter condition is True, else None
         def map_function(batch, *args, **kwargs):
             if with_indices:
                 indices = kwargs.pop("indices")
@@ -319,7 +342,7 @@
                 if batched:
                     results = []
                     for i, example in enumerate(batch):
-                        if function(example, indices[i], **kwargs):
+                        if function(example, indices[i], **fn_kwargs):
                             results.append(example)
                     return results
                 else:
@@ -327,7 +350,7 @@
             else:
                 if batched:
                     results = []
-                    for example in batch:
+                    for example in batch if batched else [batch]:
                         if function(example, **fn_kwargs):
                             results.append(example)
                     return results
@@ -335,6 +358,7 @@
                     return batch if function(batch, **fn_kwargs) else None
 
         return self.map(
+            map_function,
             batched=True,
             with_indices=with_indices,
             input_columns=input_columns,
@@ -343,6 +367,7 @@
             remove_columns=remove_columns,
             keep_in_memory=keep_in_memory,
             load_from_cache_file=load_from_cache_file,
+            cache_file_name=cache_file_name,
             writer_batch_size=writer_batch_size,
             features=features,
             disable_nullable=disable_nullable,
@@ -351,6 +376,7 @@
             desc=desc,
             fn_kwargs=fn_kwargs,
             num_proc=num_proc,
+            suffix_type=suffix_type,
         )
 
     def _map_single(
@@ -364,6 +390,7 @@
         remove_columns: Optional[List[str]] = None,
         keep_in_memory: bool = False,
         load_from_cache_file: bool = True,
+        cache_file_name: Optional[str] = None,
         writer_batch_size: Optional[int] = 1000,
         features: Optional[Features] = None,
         disable_nullable: bool = False,
@@ -372,6 +399,7 @@
         desc: Optional[str] = None,
         fn_kwargs: Optional[dict] = None,
         num_proc: Optional[int] = None,
+        suffix_type: Optional[str] = None,
     ) -> "Dataset":
         """Apply a function to all the elements in the table in batches
         and update the table so that the dataset only includes examples according to the filter function.
@@ -381,6 +409,8 @@
                 - `function(example: Dict) -> bool` if `with_indices=False`
                 - `function(example: Dict, indices: int) -> bool` if `with_indices=True`
             with_indices (`bool`, default: `False`): Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.
+            input_columns (`Optional[List[str]]`, default: `None`): The columns to be passed into `function` as
+                positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.
             batch_size (`Optional[int]`, default: `1000`): Number of examples per batch provided to `function` if `batched=True`
                 `batch_size <= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`
             remove_columns (`Optional[List[str]]`, default: `None`): Remove a selection of columns while doing the mapping.
@@ -389,6 +419,8 @@
             keep_in_memory (`bool`, default: `False`): Keep the dataset in memory instead of writing it to a cache file.
             load_from_cache_file (`bool`, default: `True`): If a cache file storing the current computation from `function`
                 can be identified, use it instead of recomputing.
+            cache_file_name (`Optional[str]`, default: `None`): Provide the name of a cache file to use to store the
+                results of the computation instead of the automatically generated cache file name.
             writer_batch_size (`int`, default: `1000`): Number of rows per write operation for the cache file writer.
                 Higher value gives smaller cache files, lower value consume less temporary memory while running `.map()`.
             disable_nullable (`bool`, default: `True`): Allow null values in the table.
@@ -396,6 +428,8 @@
                 `function` returns a dict, the key in the output dict. If not provided, will use the key from the input dict if `function` returns a dict.
             desc (`Optional[str]`, default: `None`): Meaningful description to be displayed alongside with the progress bar while mapping examples.
             fn_kwargs (`Optional[Dict]`, default: `None`): Keyword arguments to be passed to `function`
+            num_proc (`Optional[int]`, default: `None`): Number of processes for multiprocessing. By default it doesn't
+                use multiprocessing.
             suffix_type (`Optional[str]`, default: `None`): Suffix type for the cache file name. If not provided, will use the default suffix type.
 
         Returns:
@@ -403,6 +437,7 @@
         """
         assert num_proc is None or num_proc == 1, "filter doesn't support multiprocessing yet"
 
+        # Transform the filter function into a map function that returns the example if filter condition is True, else None
         def map_function(batch, *args, **kwargs):
             if with_indices:
                 indices = kwargs.pop("indices")
@@ -410,7 +445,7 @@
                 if batched:
                     results = []
                     for i, example in enumerate(batch):
-                        if function(example, indices[i], **kwargs):
+                        if function(example, indices[i], **fn_kwargs):
                             results.append(example)
                     return results
                 else:
@@ -418,7 +453,7 @@
             else:
                 if batched:
                     results = []
-                    for example in batch:
+                    for example in batch if batched else [batch]:
                         if function(example, **fn_kwargs):
                             results.append(example)
                     return results
@@ -426,6 +461,7 @@
                     return batch if function(batch, **fn_kwargs) else None
 
         return self._map_single(
+            map_function,
             batched=True,
             with_indices=with_indices,
             input_columns=input_columns,
@@ -434,6 +470,7 @@
             remove_columns=remove_columns,
             keep_in_memory=keep_in_memory,
             load_from_cache_file=load_from_cache_file,
+            cache_file_name=cache_file_name,
             writer_batch_size=writer_batch_size,
             features=features,
             disable_nullable=disable_nullable,
@@ -442,6 +479,7 @@
             desc=desc,
             fn_kwargs=fn_kwargs,
             num_proc=num_proc,
+            suffix_type=suffix_type,
         )
 
     def flatten_indices(
@@ -456,6 +494,7 @@
         remove_columns: Optional[List[str]] = None,
         keep_in_memory: bool = False,
         load_from_cache_file: bool = True,
+        cache_file_name: Optional[str] = None,
         writer_batch_size: Optional[int] = 1000,
         features: Optional[Features] = None,
         disable_nullable: bool = False,
@@ -464,6 +503,7 @@
         desc: Optional[str] = None,
         fn_kwargs: Optional[dict] = None,
         num_proc: Optional[int] = None,
+        suffix_type: Optional[str] = None,
     ) -> "Dataset":
         """Apply a function to all the elements in the table in batches
         and update the table so that the dataset only includes examples according to the filter function.
@@ -473,6 +513,8 @@
                 - `function(example: Dict) -> bool` if `with_indices=False`
                 - `function(example: Dict, indices: int) -> bool` if `with_indices=True`
             with_indices (`bool`, default: `False`): Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.
+            input_columns (`Optional[List[str]]`, default: `None`): The columns to be passed into `function` as
+                positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.
             batch_size (`Optional[int]`, default: `1000`): Number of examples per batch provided to `function` if `batched=True`
                 `batch_size <= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`
             remove_columns (`Optional[List[str]]`, default: `None`): Remove a selection of columns while doing the mapping.
@@ -481,6 +523,8 @@
             keep_in_memory (`bool`, default: `False`): Keep the dataset in memory instead of writing it to a cache file.
             load_from_cache_file (`bool`, default: `True`): If a cache file storing the current computation from `function`
                 can be identified, use it instead of recomputing.
+            cache_file_name (`Optional[str]`, default: `None`): Provide the name of a cache file to use to store the
+                results of the computation instead of the automatically generated cache file name.
             writer_batch_size (`int`, default: `1000`): Number of rows per write operation for the cache file writer.
                 Higher value gives smaller cache files, lower value consume less temporary memory while running `.map()`.
             disable_nullable (`bool`, default: `True`): Allow null values in the table.
@@ -488,6 +532,8 @@
                 `function` returns a dict, the key in the output dict. If not provided, will use the key from the input dict if `function` returns a dict.
             desc (`Optional[str]`, default: `None`): Meaningful description to be displayed alongside with the progress bar while mapping examples.
             fn_kwargs (`Optional[Dict]`, default: `None`): Keyword arguments to be passed to `function`
+            num_proc (`Optional[int]`, default: `None`): Number of processes for multiprocessing. By default it doesn't
+                use multiprocessing.
             suffix_type (`Optional[str]`, default: `None`): Suffix type for the cache file name. If not provided, will use the default suffix type.
 
         Returns:
@@ -495,6 +541,7 @@
         """
         assert num_proc is None or num_proc == 1, "filter doesn't support multiprocessing yet"
 
+        # Transform the filter function into a map function that returns the example if